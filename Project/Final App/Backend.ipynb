{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCSV = pd.read_csv('jugaad(1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baby by Justin Bieber (shitty popularity)\n",
    "userLyrics = \"Ooh whoa, ooh whoa, ooh whoa You know you love me, I know you care Just shout whenever and I'll be there You are my love, you are my heart And we will never, ever, ever be apart Are we an item? Girl quit playin' We're just friends, what are you sayin' Said there's another, look right in my eyes My first love, broke my heart for the first time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basicLyricsProcessing(userLyrics):\n",
    "    #Everything in lowercase\n",
    "    lowerCase = lambda x: \" \".join(x.lower() for x in str(x).split())\n",
    "    userLyrics = lowerCase(userLyrics)\n",
    "\n",
    "    #Removing punctuation that does not add meaning to the song\n",
    "    userLyrics = userLyrics.replace('[^\\w\\s]','')\n",
    "    \n",
    "    #Removing of stop words\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    stop = stopwords.words('english')\n",
    "    removeStopWords = lambda x: \" \".join(x for x in str(x).split() if x not in stop)\n",
    "    userLyrics = removeStopWords(userLyrics)\n",
    "    \n",
    "    #Correction of Spelling mistakes\n",
    "    from textblob import TextBlob\n",
    "    spellingMistake = lambda x: str(TextBlob(x).correct())\n",
    "    userLyrics = spellingMistake(userLyrics)\n",
    "    \n",
    "    #Lemmatization is basically converting a word into its root word. It is preferred over Stemming.\n",
    "    from textblob import Word\n",
    "    lemmatize = lambda x: \" \".join([Word(word).lemmatize() for word in x.split()])\n",
    "    userLyrics = lemmatize(userLyrics)\n",
    "    \n",
    "    #CountVectorization of user lyrics\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    user_bow = CountVectorizer(max_features=1000,\n",
    "                          lowercase=True,\n",
    "                          ngram_range=(1,1),\n",
    "                          analyzer = \"word\").fit([userLyrics])\n",
    "    \n",
    "    #Bag of Words conversion of user lyrics\n",
    "    user_lyrics_bow = bow.transform([userLyrics])\n",
    "    \n",
    "    #Tf-idf transforming of user lyrics\n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "    user_tfidf_transformer = TfidfTransformer().fit(user_lyrics_bow)\n",
    "    user_lyrics_tfidf = user_tfidf_transformer.transform(user_lyrics_bow)\n",
    "    return user_lyrics_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(max_features=1000,\n",
    "                      lowercase=True,\n",
    "                      ngram_range=(1,1),\n",
    "                      analyzer = \"word\").fit(testCSV['Lyrics'].values.astype(str))\n",
    "len(bow.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (284, 1000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10058"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_bow = bow.transform(testCSV['Lyrics'].values.astype(str))\n",
    "print('Shape of Sparse Matrix: ', lyrics_bow.shape)\n",
    "lyrics_bow.nnz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame()\n",
    "df['lyrics']=list(lyrics_bow.toarray())\n",
    "df['hit'] =  testCSV['Hit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(df['lyrics'].tolist(), df['hit'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#user_bow = basicLyricsProcessing(userLyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_user = pd.DataFrame()\n",
    "df_user['lyrics']=list(basicLyricsProcessing(userLyrics).toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prediction = model.predict(df_user['lyrics'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
