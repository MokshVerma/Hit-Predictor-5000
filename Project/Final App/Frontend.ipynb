{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (703, 1000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "testCSV = pd.read_csv('jugaad(processed lyrics).csv')\n",
    "\n",
    "#Baby by Justin Bieber (shitty popularity)\n",
    "#userLyrics = \"Ooh whoa, ooh whoa, ooh whoa You know you love me, I know you care Just shout whenever and I'll be there You are my love, you are my heart And we will never, ever, ever be apart Are we an item? Girl quit playin' We're just friends, what are you sayin' Said there's another, look right in my eyes My first love, broke my heart for the first time\"\n",
    "\n",
    "# def basicLyricsProcessing(userLyrics):\n",
    "    \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(max_features=1000,\n",
    "                      lowercase=True,\n",
    "                      ngram_range=(1,1),\n",
    "                      analyzer = \"word\").fit(testCSV['Lyrics'].values.astype(str))\n",
    "len(bow.vocabulary_)\n",
    "\n",
    "\n",
    "lyrics_bow = bow.transform(testCSV['Lyrics'].values.astype(str))\n",
    "print('Shape of Sparse Matrix: ', lyrics_bow.shape)\n",
    "lyrics_bow.nnz\n",
    "\n",
    "df= pd.DataFrame()\n",
    "df['lyrics']=list(lyrics_bow.toarray())\n",
    "df['hit'] =  testCSV['Hit']\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(df['lyrics'].tolist(), df['hit'].tolist())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    userLyrics = lyricsTextBox.get(1.0,\"end-1c\")\n",
    "    #Everything in lowercase\n",
    "    lowerCase = lambda x: \" \".join(x.lower() for x in str(x).split())\n",
    "    userLyrics = lowerCase(userLyrics)\n",
    "\n",
    "    #Removing punctuation that does not add meaning to the song\n",
    "    userLyrics = userLyrics.replace('[^\\w\\s]','')\n",
    "    \n",
    "    #Removing of stop words\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    stop = stopwords.words('english')\n",
    "    removeStopWords = lambda x: \" \".join(x for x in str(x).split() if x not in stop)\n",
    "    userLyrics = removeStopWords(userLyrics)\n",
    "    \n",
    "    #Correction of Spelling mistakes\n",
    "    from textblob import TextBlob\n",
    "    spellingMistake = lambda x: str(TextBlob(x).correct())\n",
    "    userLyrics = spellingMistake(userLyrics)\n",
    "    \n",
    "    #Lemmatization is basically converting a word into its root word. It is preferred over Stemming.\n",
    "    from textblob import Word\n",
    "    lemmatize = lambda x: \" \".join([Word(word).lemmatize() for word in x.split()])\n",
    "    userLyrics = lemmatize(userLyrics)\n",
    "    \n",
    "    #CountVectorization of user lyrics\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    user_bow = CountVectorizer(max_features=1000,\n",
    "                          lowercase=True,\n",
    "                          ngram_range=(1,1),\n",
    "                          analyzer = \"word\").fit([userLyrics])\n",
    "    \n",
    "    #Bag of Words conversion of user lyrics\n",
    "    user_lyrics_bow = bow.transform([userLyrics])\n",
    "    \n",
    "    #Tf-idf transforming of user lyrics\n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "    user_tfidf_transformer = TfidfTransformer().fit(user_lyrics_bow)\n",
    "    user_lyrics_tfidf = user_tfidf_transformer.transform(user_lyrics_bow)\n",
    "    df_user = pd.DataFrame()\n",
    "    df_user['lyrics']=list(user_lyrics_tfidf.toarray())\n",
    "\n",
    "\n",
    "    user_prediction = model.predict(df_user['lyrics'].tolist())\n",
    "    if(user_prediction[0] == 1):\n",
    "        resultLabel.config(text = 'Song is Hit')\n",
    "    else:\n",
    "        resultLabel.config(text = 'Song is not Hit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\moksh\\Anaconda3\\lib\\tkinter\\__init__.py\", line 1702, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-13-fc2c91d75e94>\", line 32, in predict\n",
      "    analyzer = \"word\").fit([userLyrics])\n",
      "  File \"C:\\Users\\moksh\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 836, in fit\n",
      "    self.fit_transform(raw_documents)\n",
      "  File \"C:\\Users\\moksh\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 869, in fit_transform\n",
      "    self.fixed_vocabulary_)\n",
      "  File \"C:\\Users\\moksh\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 811, in _count_vocab\n",
      "    raise ValueError(\"empty vocabulary; perhaps the documents only\"\n",
      "ValueError: empty vocabulary; perhaps the documents only contain stop words\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "import tkinter.ttk as ttk\n",
    "\n",
    "\n",
    "\n",
    "# creating root\n",
    "root = tk.Tk()\n",
    "root.geometry(\"600x500\")\n",
    "rows = 0\n",
    "\n",
    "while rows < 2:\n",
    "    root.rowconfigure(rows, weight=1)\n",
    "    root.columnconfigure(rows, weight=1)\n",
    "    rows += 1\n",
    "\n",
    "# creating a frame for storing all widgets\n",
    "AppFrame = tk.Frame(root)\n",
    "AppFrame.grid(row=0, column=0)\n",
    "\n",
    "# Creating label for title\n",
    "AppTitle = tk.Label(AppFrame, text=\"Hit Predictor 5000\", font=(\"Arial\", 30))\n",
    "AppTitle.grid(row=0, column=0)\n",
    "AppTitle2 = tk.Label(AppFrame, text=\"Patent Pending\", font=(\"Arial\", 5))\n",
    "AppTitle2.grid(row=0, column=1)\n",
    "\n",
    "''' Creating the first tab of the application... this tab is for the songwriter.'''\n",
    "# Creating tabs for 2 use cases\n",
    "notebook = ttk.Notebook(AppFrame)\n",
    "notebook.grid(row=2, column=0, sticky=\"W\", rowspan=100, columnspan=230)\n",
    "\n",
    "# Define our first Tab. This tab contains textbox for\n",
    "# entering lyrics and button for applying algorithm.\n",
    "page1 = ttk.Frame(root)\n",
    "notebook.add(page1, text='Lyrics Analysis')\n",
    "\n",
    "# Label above textbox to tell user to \"Enter lyrics Here\".\n",
    "EnterLyricsHereLabel = ttk.Label(page1, text=\"Enter Lyrics here:\", padding=5)\n",
    "EnterLyricsHereLabel.grid(row=1, column=0)\n",
    "\n",
    "# Now create textbox in this \"Lyrics Analysis\" tab. Lyrics are input in this textbox\n",
    "lyricsTextBox = tk.Text(page1, height=20, width=50)\n",
    "lyricsTextBox.grid(row=2, column=0)# , rowspan=50, columnspan=50)\n",
    "\n",
    "\n",
    "# Button for Applying processing and prediciton to Lyrics.\n",
    "processButton = ttk.Button(page1, text=\"Apply Processing\", width=40, command=predict)\n",
    "processButton.grid(row=3, column=0)\n",
    "\n",
    "# Label for showcasing the result.\n",
    "resultLabel = ttk.Label(page1, text=\"\\\"Result will be shown here inplace of this text\\\"\",\n",
    "                             font=(\"Arial\", 20))\n",
    "resultLabel.grid(row=5, column=0)\n",
    "\n",
    "'''  This part of code now declares the page2, use case of music production team.\n",
    "'''\n",
    "\n",
    "''' Creating page2 for Music Production company use cases features'''\n",
    "page2 = ttk.Frame(root)\n",
    "notebook.add(page2, text='Music Extras')\n",
    "\n",
    "# main loop the root window\n",
    "root.mainloop()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
